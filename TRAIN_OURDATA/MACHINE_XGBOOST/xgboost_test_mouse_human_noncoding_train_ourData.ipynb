{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "tr_data = pd.read_table(\"shuf_total_train_human_mouse\", sep='\\t', encoding='utf-8', engine='python')\n",
    "tr_data = tr_data.drop(['#ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_hum_data = pd.read_table(\"shuf_tot_human\", sep='\\t', encoding='utf-8', engine='python')\n",
    "ts_hum_data = ts_hum_data.drop(['#ID'], axis=1)\n",
    "ts_zebrafish_data = pd.read_table(\"shuf_tot_zebrafish\", sep='\\t', encoding='utf-8', engine='python')\n",
    "ts_zebrafish_data = ts_zebrafish_data.drop(['#ID'], axis=1)\n",
    "ts_mouse_data = pd.read_table(\"shuf_tot_mouse\", sep='\\t', encoding='utf-8', engine='python')\n",
    "ts_mouse_data = ts_mouse_data.drop(['#ID'], axis=1)\n",
    "ts_gen_data = pd.read_table(\"fin_shuf_gen\", sep='\\t', encoding='utf-8', engine='python')\n",
    "ts_gen_data = ts_gen_data.drop(['#ID'], axis=1)\n",
    "ts_mouse_gen_data = pd.read_table(\"total_v18_mouse_feat\", sep='\\t', encoding='utf-8', engine='python')\n",
    "ts_mouse_gen_data = ts_mouse_gen_data.drop(['#ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_model = pd.get_dummies(tr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_hum_model = pd.get_dummies(ts_hum_data)\n",
    "ts_mouse_model = pd.get_dummies(ts_mouse_data)\n",
    "ts_zebrafish_model = pd.get_dummies(ts_zebrafish_data)\n",
    "ts_gen_model = pd.get_dummies(ts_gen_data)\n",
    "ts_mouse_gen_model = pd.get_dummies(ts_mouse_gen_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_feat = ['instability', 'gravy', 'Mw', 'pI', 'PW', 'peptide_length']\n",
    "rna_feat = ['ORF_coverage', 'ORF_integrity', 'GC1', 'GC2', 'GC3']\n",
    "dna_feat = ['transcript_length', 'stop_codon_num', 'Fickett_score']\n",
    "\n",
    "label = ['#label_noncoding']\n",
    "\n",
    "\n",
    "\n",
    "y_train = tr_model[label]\n",
    "\n",
    "x_prot_train = tr_data[prot_feat]\n",
    "x_rna_train = tr_data[rna_feat]\n",
    "x_dna_train = tr_data[dna_feat]\n",
    "\n",
    "final_feats = []\n",
    "\n",
    "f_test = ['transcript_length', 'Fickett_score', 'ORF_coverage', 'ORF_integrity', 'GC1', 'GC2', 'GC3', 'stop_codon_num', 'instability', 'gravy', 'pI', 'Mw', 'PW']\n",
    "l_test = ['#label_noncoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = XGBClassifier(silent=True,  scale_pos_weight=1,learning_rate=0.2,colsample_bytree = 0.4,subsample = 0.8,objective='binary:logistic', n_estimators=1000, \n",
    "#reg_alpha = 0.3,max_depth=10, gamma=5)\n",
    "model = XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=7, min_child_weight=0, gamma=0, subsample=0.9, \n",
    "                      colsample_bytree=0.6, objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "#model = XGBClassifier(gamma=4, max_depth = 10, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_fin_feats = ['gravy', 'Mw', 'pI', 'GC3', 'Fickett_score']\n",
    "\n",
    "x_train = tr_model[fin_fin_feats]\n",
    "\n",
    "x_hum_test = ts_hum_model[fin_fin_feats]\n",
    "y_hum_test = ts_hum_model[l_test]\n",
    "\n",
    "x_mouse_test = ts_mouse_model[fin_fin_feats]\n",
    "y_mouse_test = ts_mouse_model[l_test]\n",
    "\n",
    "x_zebrafish_test = ts_zebrafish_model[fin_fin_feats]\n",
    "y_zebrafish_test = ts_zebrafish_model[l_test]\n",
    "\n",
    "x_gen_test = ts_gen_model[fin_fin_feats]\n",
    "y_gen_test = ts_gen_model[l_test]\n",
    "\n",
    "x_mouse_gen_test = ts_mouse_gen_model[fin_fin_feats]\n",
    "y_mouse_gen_test = ts_mouse_gen_model[l_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thesis/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thesis/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n",
      "Accuracy: 90.23%\n",
      "Fold : 2\n",
      "Accuracy: 90.52%\n",
      "Fold : 3\n",
      "Accuracy: 91.20%\n",
      "Fold : 4\n",
      "Accuracy: 89.80%\n",
      "Fold : 5\n",
      "Accuracy: 90.40%\n",
      "Fold : 6\n",
      "Accuracy: 90.20%\n",
      "Fold : 7\n",
      "Accuracy: 90.53%\n",
      "Fold : 8\n",
      "Accuracy: 90.40%\n",
      "Fold : 9\n",
      "Accuracy: 90.43%\n",
      "Fold : 10\n",
      "Accuracy: 90.03%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(x_train)\n",
    "#KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "cnt = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    cnt += 1\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    xx_train, xx_test = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "    yy_train, yy_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    model.fit(xx_train, yy_train)\n",
    "    yy_pred = model.predict(xx_test)\n",
    "    accuracy = accuracy_score(yy_test, yy_pred)\n",
    "    print(\"Fold : %d\"%cnt)\n",
    "    print(\"Accuracy: %.2f%%\"%(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal\n",
    "y_hum_pred = model.predict(x_hum_test)\n",
    "y_mouse_pred = model.predict(x_mouse_test)\n",
    "y_zebrafish_pred = model.predict(x_zebrafish_test)\n",
    "y_gen_pred = model.predict(x_gen_test)\n",
    "y_mouse_gen_pred = model.predict(x_mouse_gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy human: 95.80%\n",
      "Accuracy mouse: 93.81%\n",
      "Accuracy zebrafish: 86.22%\n",
      "Accuracy gen: 92.51%\n",
      "Accuracy mouse gen: 96.09%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_hum_test, y_hum_pred)\n",
    "print(\"Accuracy human: %.2f%%\" % (accuracy * 100.0))\n",
    "accuracy = accuracy_score(y_mouse_test, y_mouse_pred)\n",
    "print(\"Accuracy mouse: %.2f%%\" % (accuracy * 100.0))\n",
    "accuracy = accuracy_score(y_zebrafish_test, y_zebrafish_pred)\n",
    "print(\"Accuracy zebrafish: %.2f%%\" % (accuracy * 100.0))\n",
    "accuracy = accuracy_score(y_gen_test, y_gen_pred)\n",
    "print(\"Accuracy gen: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "accuracy = accuracy_score(y_mouse_gen_test, y_mouse_gen_pred)\n",
    "print(\"Accuracy mouse gen: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy human: 95.80%\n",
    "Accuracy mouse: 93.81%\n",
    "Accuracy zebrafish: 86.22%\n",
    "Accuracy gen: 92.51%\n",
    "Accuracy mouse gen: 96.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['class non coding', 'class coding']\n",
    "print(classification_report(y_hum_test, y_hum_pred, target_names=target_names))\n",
    "\n",
    "#target_names = ['class non coding', 'class coding']\n",
    "print(classification_report(y_mouse_test, y_mouse_pred, target_names=target_names))\n",
    "\n",
    "#target_names = ['class non coding', 'class coding']\n",
    "print(classification_report(y_zebrafish_test, y_zebrafish_pred, target_names=target_names))\n",
    "\n",
    "print(classification_report(y_gen_test, y_gen_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from __future__ import division\n",
    "tn, fp, fn, tp = confusion_matrix(y_hum_test, y_hum_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(specificity)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_mouse_test, y_mouse_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(specificity)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_zebrafish_test, y_zebrafish_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(specificity)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_gen_test, y_gen_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_hum = confusion_matrix(y_hum_test, y_hum_pred)\n",
    "print(cm_hum)\n",
    "cm_mouse = confusion_matrix(y_mouse_test, y_mouse_pred)\n",
    "print(cm_mouse)\n",
    "cm_zebrafish = confusion_matrix(y_zebrafish_test, y_zebrafish_pred)\n",
    "print(cm_zebrafish)\n",
    "cm_gen = confusion_matrix(y_gen_test, y_gen_pred)\n",
    "print(cm_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print roc_auc_score(y_hum_test, y_hum_pred)\n",
    "\n",
    "print roc_auc_score(y_mouse_test, y_mouse_pred)\n",
    "\n",
    "print roc_auc_score(y_zebrafish_test, y_zebrafish_pred)\n",
    "\n",
    "print roc_auc_score(y_gen_test, y_gen_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision : the ability of the classifier not to label as positive a sample that is negative.\n",
    "#recall : the ability of the classifier to find all the positive samples\n",
    "#f1-score :  F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0\n",
    "# support : The support is the number of occurrences of each class in y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_hum_test, y_hum_pred)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.yticks(np.arange(0.0, 1.2, step=0.05))\n",
    "plt.xticks(np.arange(0.0, 1.2, step=0.1))\n",
    "#print(lock, labels)\n",
    "plt.xlim([0.0,1.1])\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "plt.xlabel('False Positive Rate(Specificity)')\n",
    "plt.autoscale(enable = False, axis = 'both', tight = True)\n",
    "plt.rcParams['figure.figsize'] = [6, 5]\n",
    "#print(plt.grid)\n",
    "#plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_mouse_test, y_mouse_pred)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.yticks(np.arange(0.0, 1.2, step=0.05))\n",
    "plt.xticks(np.arange(0.0, 1.2, step=0.1))\n",
    "#print(lock, labels)\n",
    "plt.xlim([0.0,1.1])\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "plt.xlabel('False Positive Rate(Specificity)')\n",
    "plt.autoscale(enable = False, axis = 'both', tight = True)\n",
    "plt.rcParams['figure.figsize'] = [6, 5]\n",
    "#print(plt.grid)\n",
    "#plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_zebrafish_test, y_zebrafish_pred)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.yticks(np.arange(0.0, 1.2, step=0.05))\n",
    "plt.xticks(np.arange(0.0, 1.2, step=0.1))\n",
    "#print(lock, labels)\n",
    "plt.xlim([0.0,1.1])\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "plt.xlabel('False Positive Rate(Specificity)')\n",
    "plt.autoscale(enable = False, axis = 'both', tight = True)\n",
    "plt.rcParams['figure.figsize'] = [6, 5]\n",
    "#print(plt.grid)\n",
    "#plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_gen_test, y_gen_pred)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0,1],[0,1], 'r--')\n",
    "plt.yticks(np.arange(0.0, 1.2, step=0.05))\n",
    "plt.xticks(np.arange(0.0, 1.2, step=0.1))\n",
    "#print(lock, labels)\n",
    "plt.xlim([0.0,1.1])\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "plt.xlabel('False Positive Rate(Specificity)')\n",
    "plt.autoscale(enable = False, axis = 'both', tight = True)\n",
    "plt.rcParams['figure.figsize'] = [6, 5]\n",
    "#print(plt.grid)\n",
    "#plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
